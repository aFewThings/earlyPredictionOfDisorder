{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pose Estimation Models\n",
    "\n",
    "references:\n",
    "- stacked hourglass networks for human pose estimation: [https://arxiv.org/abs/1603.06937](https://arxiv.org/abs/1603.06937)\n",
    "- simple baselines for human pose estimation and tracking: [https://arxiv.org/abs/1804.06208](https://arxiv.org/abs/1804.06208)\n",
    "- [https://curt-park.github.io/2018-07-03/stacked-hourglass-networks-for-human-pose-estimation/](https://curt-park.github.io/2018-07-03/stacked-hourglass-networks-for-human-pose-estimation/)\n",
    "\n",
    "code references: \n",
    "- [https://github.com/bearpaw/pytorch-pose](https://github.com/bearpaw/pytorch-pose)\n",
    "- [https://github.com/princeton-vl/pose-hg-train](https://github.com/princeton-vl/pose-hg-train)\n",
    "\n",
    "dataset annotatation references:\n",
    "- [https://github.com/bearpaw/pytorch-pose](https://github.com/bearpaw/pytorch-pose)\n",
    "- [https://github.com/HRNet/HRNet-Human-Pose-Estimation](https://github.com/HRNet/HRNet-Human-Pose-Estimation)\n",
    "\n",
    "### Stacked Hourglass (2016)\n",
    "\n",
    "#### Multi-Stage Architecture\n",
    "\n",
    "<img src=\"./src_imgs/10.png\" width=600><br/>\n",
    "\n",
    "<img src=\"./src_imgs/9.jpg\"><br/>\n",
    "\n",
    "Stacked Hourglass는 말그대로 모래시계 모양의 동일한 Network를 여러겹 쌓아서 만든 모델입니다. 이렇게 단일 네트워크를 여러겹 쌓는 구조는 Pose Estimation 분야에서 종종 볼 수 있습니다. 그 이유는 각 Stack마다 heatmap을 출력해보면 알 수 있는데, 2번째 그림과 같이 결과를 refine 시킬 수 있다는 장점을 갖기 때문입니다. 이러한 구조를 Multi-Stage Architecture라 하며 Single-Stage Architecture보다 정밀한 결과를 얻을 것이라는 아이디어에서 출발하였습니다. \n",
    "\n",
    "#### Multi-Scale\n",
    "\n",
    "|![](./src_imgs/6.png)|\n",
    "|:---:|\n",
    "|*Hourglass*|\n",
    "\n",
    "|![](./src_imgs/7.png)|\n",
    "|:---:|\n",
    "|*Stacked Hourglass (two-stack)*|\n",
    "\n",
    "Stacked Hourglass가 포즈를 추출하는 것에 있어 우수한 성능을 내는 또 하나의 이유는 이미지의 모든 scale에서 정보를 얻을 수 있기 때문입니다. 단일 Hourglass network는 high resolution에서 low resolution으로 features를 만들어내는 **Downsampling Process**, 다시 low resolution에서 high resolution으로 resolution을 복구시키는 **Upsampling Process**를 통해 다양한 scale에서 정보를 얻습니다 (e.g. 64->32->16->8->4, 4->8->16->32->64). \n",
    "\n",
    "#### Residual Block / Intermediate Supervision\n",
    "\n",
    "|![](./src_imgs/11.png)|\n",
    "|:---:|\n",
    "|*Residual Block*|\n",
    "\n",
    "|![](./src_imgs/12.png)|\n",
    "|:---:|\n",
    "|*Intermediate Supervision*|\n",
    "\n",
    "Multi-Stage 구조의 가장 큰 문제는 네트워크가 쌓일수록 layer가 깊어져서 Deep Neural Net의 고질적인 문제인 vanishing gradient(깊은 layer에서는 gradient의 영향력이 작아지는 문제)와 degradation(얕은 layer보다 깊은 layer를 갖는 모델이 오히려 성능이 안좋아지는 문제)이 발생한다는 점입니다. \n",
    "이것을 Stacked Hourglass는 residual block과 intermediate supervision을 차용함으로 학습 문제를 개선하였습니다. 앞서 Hourglass 구조를 나타내는 그림에서 각 상자는 residual block을 의미합니다.\n",
    "\n",
    "Residual block의 특징은 module의 input과 output(convolution + activation function 결과)을 element-wise addition한다는 것입니다. 이러한 구조는 gradient를 유지하기 쉽게 만들어주어 vanishing gradient가 발생하기 어렵게 만든다는 장점이 있습니다.\n",
    "\n",
    "Intermediate supervision이란 각 stack 끝마다 loss layer를 추가하는 것으로 gradient를 비효율적이지만 효과적으로 전달하는 방법입니다. 깊은 stack일수록 gradient의 값이 0에 가깝다는 문제를 직접 각 stack에 gradient를 전달하는 것으로 해결하였습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 정의 및 구조 시각화\n",
    "\n",
    "이제 Hourglass 모델을 정의하고 stack=2 만큼 쌓은 네트워크의 구조를 시각화하겠습니다.\n",
    "\n",
    "Hourglass 모델을 이루는 기본 block은 앞서 말했듯이 Residual block을 사용합니다.<br/>\n",
    "Block의 입력인 x와 컨볼루션 결과인 out이 함께 더해져서 연결되는 모습(skip connection)을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# residual block\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=True)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=True)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 2, kernel_size=1, bias=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 정의한 residual block은 다음 hourglass module에서 기본 block으로 사용됩니다. \n",
    "\n",
    "hourglass에선 다양한 scale의 resolution에서 정보를 얻기 위해 MaxPooling을 이용해 downsampling 하고, 최근접 이웃보간을 통해 upsampling 합니다 (`F.max_pool2d()`, `F.interpolate()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hourglass(nn.Module):\n",
    "    def __init__(self, block, num_blocks, planes, depth):\n",
    "        super(Hourglass, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.block = block\n",
    "        self.hg = self._make_hour_glass(block, num_blocks, planes, depth)\n",
    "\n",
    "    def _make_residual(self, block, num_blocks, planes):\n",
    "        layers = []\n",
    "        for i in range(0, num_blocks):\n",
    "            layers.append(block(planes*block.expansion, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_hour_glass(self, block, num_blocks, planes, depth):\n",
    "        hg = []\n",
    "        for i in range(depth):\n",
    "            res = []\n",
    "            for j in range(3):\n",
    "                res.append(self._make_residual(block, num_blocks, planes))\n",
    "            if i == 0:\n",
    "                res.append(self._make_residual(block, num_blocks, planes))\n",
    "            hg.append(nn.ModuleList(res))\n",
    "        return nn.ModuleList(hg)\n",
    "\n",
    "    def _hour_glass_forward(self, n, x):\n",
    "        up1 = self.hg[n-1][0](x)\n",
    "        low1 = F.max_pool2d(x, 2, stride=2)\n",
    "        low1 = self.hg[n-1][1](low1)\n",
    "\n",
    "        if n > 1:\n",
    "            low2 = self._hour_glass_forward(n-1, low1)\n",
    "        else:\n",
    "            low2 = self.hg[n-1][3](low1)\n",
    "        low3 = self.hg[n-1][2](low2)\n",
    "        up2 = F.interpolate(low3, scale_factor=2)\n",
    "        out = up1 + up2\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._hour_glass_forward(self.depth, x)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 Hourglass 모듈을 stack으로 쌓을 수 있는 네트워크를 정의합니다.\n",
    "\n",
    "`HourglassNet`은 hourglass 스택 개수(`num_stack`), 한 block에 포함된 residual block 개수(`num_block`), parts 개수(`num_classes`)를 조정할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " class HourglassNet(nn.Module):\n",
    "    '''Hourglass model from Newell et al ECCV 2016'''\n",
    "    def __init__(self, block, num_stacks=2, num_blocks=4, num_classes=16):\n",
    "        super(HourglassNet, self).__init__()\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.num_feats = 128\n",
    "        self.num_stacks = num_stacks\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_residual(block, self.inplanes, 1)\n",
    "        self.layer2 = self._make_residual(block, self.inplanes, 1)\n",
    "        self.layer3 = self._make_residual(block, self.num_feats, 1)\n",
    "        self.maxpool = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "        # build hourglass modules\n",
    "        ch = self.num_feats*block.expansion\n",
    "        hg, res, fc, score, fc_, score_ = [], [], [], [], [], []\n",
    "        for i in range(num_stacks):\n",
    "            hg.append(Hourglass(block, num_blocks, self.num_feats, 4))\n",
    "            res.append(self._make_residual(block, self.num_feats, num_blocks))\n",
    "            fc.append(self._make_fc(ch, ch))\n",
    "            score.append(nn.Conv2d(ch, num_classes, kernel_size=1, bias=True))\n",
    "            if i < num_stacks-1:\n",
    "                fc_.append(nn.Conv2d(ch, ch, kernel_size=1, bias=True))\n",
    "                score_.append(nn.Conv2d(num_classes, ch, kernel_size=1, bias=True))\n",
    "        self.hg = nn.ModuleList(hg)\n",
    "        self.res = nn.ModuleList(res)\n",
    "        self.fc = nn.ModuleList(fc)\n",
    "        self.score = nn.ModuleList(score)\n",
    "        self.fc_ = nn.ModuleList(fc_)\n",
    "        self.score_ = nn.ModuleList(score_)\n",
    "\n",
    "    def _make_residual(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=True),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_fc(self, inplanes, outplanes):\n",
    "        bn = nn.BatchNorm2d(inplanes)\n",
    "        conv = nn.Conv2d(inplanes, outplanes, kernel_size=1, bias=True)\n",
    "        return nn.Sequential(\n",
    "                conv,\n",
    "                bn,\n",
    "                self.relu,\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = []\n",
    "        # preprocessing\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        # stacking modules\n",
    "        for i in range(self.num_stacks):\n",
    "            y = self.hg[i](x)\n",
    "            y = self.res[i](y)\n",
    "            y = self.fc[i](y)\n",
    "            score = self.score[i](y)\n",
    "            out.append(score)\n",
    "            if i < self.num_stacks-1:\n",
    "                fc_ = self.fc_[i](y)\n",
    "                score_ = self.score_[i](score)\n",
    "                x = x + fc_ + score_\n",
    "\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack=1인 HourglassNet의 구조를 출력해보면 다음과 같습니다. \n",
    "\n",
    "레이어가 깊어질수록 output resolution이 128->64->32->16->8->4 까지 줄어들고, \n",
    "다시 4->8->16->32->64 까지 증가함을 볼 수 있습니다. 또한, 마지막 레이어에선 heatmap([1, 16, 64, 64])을 출력하고 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [1, 64, 128, 128]           9,472\n",
      "       BatchNorm2d-2          [1, 64, 128, 128]             128\n",
      "              ReLU-3          [1, 64, 128, 128]               0\n",
      "              ReLU-4          [1, 64, 128, 128]               0\n",
      "       BatchNorm2d-5          [1, 64, 128, 128]             128\n",
      "              ReLU-6          [1, 64, 128, 128]               0\n",
      "            Conv2d-7          [1, 64, 128, 128]           4,160\n",
      "       BatchNorm2d-8          [1, 64, 128, 128]             128\n",
      "              ReLU-9          [1, 64, 128, 128]               0\n",
      "           Conv2d-10          [1, 64, 128, 128]          36,928\n",
      "      BatchNorm2d-11          [1, 64, 128, 128]             128\n",
      "             ReLU-12          [1, 64, 128, 128]               0\n",
      "           Conv2d-13         [1, 128, 128, 128]           8,320\n",
      "           Conv2d-14         [1, 128, 128, 128]           8,320\n",
      "       Bottleneck-15         [1, 128, 128, 128]               0\n",
      "        MaxPool2d-16           [1, 128, 64, 64]               0\n",
      "      BatchNorm2d-17           [1, 128, 64, 64]             256\n",
      "             ReLU-18           [1, 128, 64, 64]               0\n",
      "           Conv2d-19           [1, 128, 64, 64]          16,512\n",
      "      BatchNorm2d-20           [1, 128, 64, 64]             256\n",
      "             ReLU-21           [1, 128, 64, 64]               0\n",
      "           Conv2d-22           [1, 128, 64, 64]         147,584\n",
      "      BatchNorm2d-23           [1, 128, 64, 64]             256\n",
      "             ReLU-24           [1, 128, 64, 64]               0\n",
      "           Conv2d-25           [1, 256, 64, 64]          33,024\n",
      "           Conv2d-26           [1, 256, 64, 64]          33,024\n",
      "       Bottleneck-27           [1, 256, 64, 64]               0\n",
      "      BatchNorm2d-28           [1, 256, 64, 64]             512\n",
      "             ReLU-29           [1, 256, 64, 64]               0\n",
      "           Conv2d-30           [1, 128, 64, 64]          32,896\n",
      "      BatchNorm2d-31           [1, 128, 64, 64]             256\n",
      "             ReLU-32           [1, 128, 64, 64]               0\n",
      "           Conv2d-33           [1, 128, 64, 64]         147,584\n",
      "      BatchNorm2d-34           [1, 128, 64, 64]             256\n",
      "             ReLU-35           [1, 128, 64, 64]               0\n",
      "           Conv2d-36           [1, 256, 64, 64]          33,024\n",
      "       Bottleneck-37           [1, 256, 64, 64]               0\n",
      "      BatchNorm2d-38           [1, 256, 64, 64]             512\n",
      "             ReLU-39           [1, 256, 64, 64]               0\n",
      "           Conv2d-40           [1, 128, 64, 64]          32,896\n",
      "      BatchNorm2d-41           [1, 128, 64, 64]             256\n",
      "             ReLU-42           [1, 128, 64, 64]               0\n",
      "           Conv2d-43           [1, 128, 64, 64]         147,584\n",
      "      BatchNorm2d-44           [1, 128, 64, 64]             256\n",
      "             ReLU-45           [1, 128, 64, 64]               0\n",
      "           Conv2d-46           [1, 256, 64, 64]          33,024\n",
      "       Bottleneck-47           [1, 256, 64, 64]               0\n",
      "      BatchNorm2d-48           [1, 256, 32, 32]             512\n",
      "             ReLU-49           [1, 256, 32, 32]               0\n",
      "           Conv2d-50           [1, 128, 32, 32]          32,896\n",
      "      BatchNorm2d-51           [1, 128, 32, 32]             256\n",
      "             ReLU-52           [1, 128, 32, 32]               0\n",
      "           Conv2d-53           [1, 128, 32, 32]         147,584\n",
      "      BatchNorm2d-54           [1, 128, 32, 32]             256\n",
      "             ReLU-55           [1, 128, 32, 32]               0\n",
      "           Conv2d-56           [1, 256, 32, 32]          33,024\n",
      "       Bottleneck-57           [1, 256, 32, 32]               0\n",
      "      BatchNorm2d-58           [1, 256, 32, 32]             512\n",
      "             ReLU-59           [1, 256, 32, 32]               0\n",
      "           Conv2d-60           [1, 128, 32, 32]          32,896\n",
      "      BatchNorm2d-61           [1, 128, 32, 32]             256\n",
      "             ReLU-62           [1, 128, 32, 32]               0\n",
      "           Conv2d-63           [1, 128, 32, 32]         147,584\n",
      "      BatchNorm2d-64           [1, 128, 32, 32]             256\n",
      "             ReLU-65           [1, 128, 32, 32]               0\n",
      "           Conv2d-66           [1, 256, 32, 32]          33,024\n",
      "       Bottleneck-67           [1, 256, 32, 32]               0\n",
      "      BatchNorm2d-68           [1, 256, 16, 16]             512\n",
      "             ReLU-69           [1, 256, 16, 16]               0\n",
      "           Conv2d-70           [1, 128, 16, 16]          32,896\n",
      "      BatchNorm2d-71           [1, 128, 16, 16]             256\n",
      "             ReLU-72           [1, 128, 16, 16]               0\n",
      "           Conv2d-73           [1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-74           [1, 128, 16, 16]             256\n",
      "             ReLU-75           [1, 128, 16, 16]               0\n",
      "           Conv2d-76           [1, 256, 16, 16]          33,024\n",
      "       Bottleneck-77           [1, 256, 16, 16]               0\n",
      "      BatchNorm2d-78           [1, 256, 16, 16]             512\n",
      "             ReLU-79           [1, 256, 16, 16]               0\n",
      "           Conv2d-80           [1, 128, 16, 16]          32,896\n",
      "      BatchNorm2d-81           [1, 128, 16, 16]             256\n",
      "             ReLU-82           [1, 128, 16, 16]               0\n",
      "           Conv2d-83           [1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-84           [1, 128, 16, 16]             256\n",
      "             ReLU-85           [1, 128, 16, 16]               0\n",
      "           Conv2d-86           [1, 256, 16, 16]          33,024\n",
      "       Bottleneck-87           [1, 256, 16, 16]               0\n",
      "      BatchNorm2d-88             [1, 256, 8, 8]             512\n",
      "             ReLU-89             [1, 256, 8, 8]               0\n",
      "           Conv2d-90             [1, 128, 8, 8]          32,896\n",
      "      BatchNorm2d-91             [1, 128, 8, 8]             256\n",
      "             ReLU-92             [1, 128, 8, 8]               0\n",
      "           Conv2d-93             [1, 128, 8, 8]         147,584\n",
      "      BatchNorm2d-94             [1, 128, 8, 8]             256\n",
      "             ReLU-95             [1, 128, 8, 8]               0\n",
      "           Conv2d-96             [1, 256, 8, 8]          33,024\n",
      "       Bottleneck-97             [1, 256, 8, 8]               0\n",
      "      BatchNorm2d-98             [1, 256, 8, 8]             512\n",
      "             ReLU-99             [1, 256, 8, 8]               0\n",
      "          Conv2d-100             [1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-101             [1, 128, 8, 8]             256\n",
      "            ReLU-102             [1, 128, 8, 8]               0\n",
      "          Conv2d-103             [1, 128, 8, 8]         147,584\n",
      "     BatchNorm2d-104             [1, 128, 8, 8]             256\n",
      "            ReLU-105             [1, 128, 8, 8]               0\n",
      "          Conv2d-106             [1, 256, 8, 8]          33,024\n",
      "      Bottleneck-107             [1, 256, 8, 8]               0\n",
      "     BatchNorm2d-108             [1, 256, 4, 4]             512\n",
      "            ReLU-109             [1, 256, 4, 4]               0\n",
      "          Conv2d-110             [1, 128, 4, 4]          32,896\n",
      "     BatchNorm2d-111             [1, 128, 4, 4]             256\n",
      "            ReLU-112             [1, 128, 4, 4]               0\n",
      "          Conv2d-113             [1, 128, 4, 4]         147,584\n",
      "     BatchNorm2d-114             [1, 128, 4, 4]             256\n",
      "            ReLU-115             [1, 128, 4, 4]               0\n",
      "          Conv2d-116             [1, 256, 4, 4]          33,024\n",
      "      Bottleneck-117             [1, 256, 4, 4]               0\n",
      "     BatchNorm2d-118             [1, 256, 4, 4]             512\n",
      "            ReLU-119             [1, 256, 4, 4]               0\n",
      "          Conv2d-120             [1, 128, 4, 4]          32,896\n",
      "     BatchNorm2d-121             [1, 128, 4, 4]             256\n",
      "            ReLU-122             [1, 128, 4, 4]               0\n",
      "          Conv2d-123             [1, 128, 4, 4]         147,584\n",
      "     BatchNorm2d-124             [1, 128, 4, 4]             256\n",
      "            ReLU-125             [1, 128, 4, 4]               0\n",
      "          Conv2d-126             [1, 256, 4, 4]          33,024\n",
      "      Bottleneck-127             [1, 256, 4, 4]               0\n",
      "     BatchNorm2d-128             [1, 256, 4, 4]             512\n",
      "            ReLU-129             [1, 256, 4, 4]               0\n",
      "          Conv2d-130             [1, 128, 4, 4]          32,896\n",
      "     BatchNorm2d-131             [1, 128, 4, 4]             256\n",
      "            ReLU-132             [1, 128, 4, 4]               0\n",
      "          Conv2d-133             [1, 128, 4, 4]         147,584\n",
      "     BatchNorm2d-134             [1, 128, 4, 4]             256\n",
      "            ReLU-135             [1, 128, 4, 4]               0\n",
      "          Conv2d-136             [1, 256, 4, 4]          33,024\n",
      "      Bottleneck-137             [1, 256, 4, 4]               0\n",
      "     BatchNorm2d-138             [1, 256, 8, 8]             512\n",
      "            ReLU-139             [1, 256, 8, 8]               0\n",
      "          Conv2d-140             [1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-141             [1, 128, 8, 8]             256\n",
      "            ReLU-142             [1, 128, 8, 8]               0\n",
      "          Conv2d-143             [1, 128, 8, 8]         147,584\n",
      "     BatchNorm2d-144             [1, 128, 8, 8]             256\n",
      "            ReLU-145             [1, 128, 8, 8]               0\n",
      "          Conv2d-146             [1, 256, 8, 8]          33,024\n",
      "      Bottleneck-147             [1, 256, 8, 8]               0\n",
      "     BatchNorm2d-148           [1, 256, 16, 16]             512\n",
      "            ReLU-149           [1, 256, 16, 16]               0\n",
      "          Conv2d-150           [1, 128, 16, 16]          32,896\n",
      "     BatchNorm2d-151           [1, 128, 16, 16]             256\n",
      "            ReLU-152           [1, 128, 16, 16]               0\n",
      "          Conv2d-153           [1, 128, 16, 16]         147,584\n",
      "     BatchNorm2d-154           [1, 128, 16, 16]             256\n",
      "            ReLU-155           [1, 128, 16, 16]               0\n",
      "          Conv2d-156           [1, 256, 16, 16]          33,024\n",
      "      Bottleneck-157           [1, 256, 16, 16]               0\n",
      "     BatchNorm2d-158           [1, 256, 32, 32]             512\n",
      "            ReLU-159           [1, 256, 32, 32]               0\n",
      "          Conv2d-160           [1, 128, 32, 32]          32,896\n",
      "     BatchNorm2d-161           [1, 128, 32, 32]             256\n",
      "            ReLU-162           [1, 128, 32, 32]               0\n",
      "          Conv2d-163           [1, 128, 32, 32]         147,584\n",
      "     BatchNorm2d-164           [1, 128, 32, 32]             256\n",
      "            ReLU-165           [1, 128, 32, 32]               0\n",
      "          Conv2d-166           [1, 256, 32, 32]          33,024\n",
      "      Bottleneck-167           [1, 256, 32, 32]               0\n",
      "       Hourglass-168           [1, 256, 64, 64]               0\n",
      "     BatchNorm2d-169           [1, 256, 64, 64]             512\n",
      "            ReLU-170           [1, 256, 64, 64]               0\n",
      "          Conv2d-171           [1, 128, 64, 64]          32,896\n",
      "     BatchNorm2d-172           [1, 128, 64, 64]             256\n",
      "            ReLU-173           [1, 128, 64, 64]               0\n",
      "          Conv2d-174           [1, 128, 64, 64]         147,584\n",
      "     BatchNorm2d-175           [1, 128, 64, 64]             256\n",
      "            ReLU-176           [1, 128, 64, 64]               0\n",
      "          Conv2d-177           [1, 256, 64, 64]          33,024\n",
      "      Bottleneck-178           [1, 256, 64, 64]               0\n",
      "          Conv2d-179           [1, 256, 64, 64]          65,792\n",
      "     BatchNorm2d-180           [1, 256, 64, 64]             512\n",
      "            ReLU-181           [1, 256, 64, 64]               0\n",
      "            ReLU-182           [1, 256, 64, 64]               0\n",
      "          Conv2d-183            [1, 16, 64, 64]           4,112\n",
      "================================================================\n",
      "Total params: 3,586,960\n",
      "Trainable params: 3,586,960\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 468.28\n",
      "Params size (MB): 13.68\n",
      "Estimated Total Size (MB): 482.71\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# hourglass\n",
    "model = HourglassNet(Bottleneck, num_stacks=1, num_blocks=1, num_classes=16).to(device)\n",
    "\n",
    "summary(model, input_size=(3, 256, 256), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [1, 64, 128, 128]           9,472\n",
      "       BatchNorm2d-2          [1, 64, 128, 128]             128\n",
      "              ReLU-3          [1, 64, 128, 128]               0\n",
      "              ReLU-4          [1, 64, 128, 128]               0\n",
      "              ReLU-5          [1, 64, 128, 128]               0\n",
      "       BatchNorm2d-6          [1, 64, 128, 128]             128\n",
      "              ReLU-7          [1, 64, 128, 128]               0\n",
      "            Conv2d-8          [1, 64, 128, 128]           4,160\n",
      "       BatchNorm2d-9          [1, 64, 128, 128]             128\n",
      "             ReLU-10          [1, 64, 128, 128]               0\n",
      "           Conv2d-11          [1, 64, 128, 128]          36,928\n",
      "      BatchNorm2d-12          [1, 64, 128, 128]             128\n",
      "             ReLU-13          [1, 64, 128, 128]               0\n",
      "           Conv2d-14         [1, 128, 128, 128]           8,320\n",
      "           Conv2d-15         [1, 128, 128, 128]           8,320\n",
      "       Bottleneck-16         [1, 128, 128, 128]               0\n",
      "        MaxPool2d-17           [1, 128, 64, 64]               0\n",
      "      BatchNorm2d-18           [1, 128, 64, 64]             256\n",
      "             ReLU-19           [1, 128, 64, 64]               0\n",
      "           Conv2d-20           [1, 128, 64, 64]          16,512\n",
      "      BatchNorm2d-21           [1, 128, 64, 64]             256\n",
      "             ReLU-22           [1, 128, 64, 64]               0\n",
      "           Conv2d-23           [1, 128, 64, 64]         147,584\n",
      "      BatchNorm2d-24           [1, 128, 64, 64]             256\n",
      "             ReLU-25           [1, 128, 64, 64]               0\n",
      "           Conv2d-26           [1, 256, 64, 64]          33,024\n",
      "           Conv2d-27           [1, 256, 64, 64]          33,024\n",
      "       Bottleneck-28           [1, 256, 64, 64]               0\n",
      "      BatchNorm2d-29           [1, 256, 64, 64]             512\n",
      "             ReLU-30           [1, 256, 64, 64]               0\n",
      "           Conv2d-31           [1, 128, 64, 64]          32,896\n",
      "      BatchNorm2d-32           [1, 128, 64, 64]             256\n",
      "             ReLU-33           [1, 128, 64, 64]               0\n",
      "           Conv2d-34           [1, 128, 64, 64]         147,584\n",
      "      BatchNorm2d-35           [1, 128, 64, 64]             256\n",
      "             ReLU-36           [1, 128, 64, 64]               0\n",
      "           Conv2d-37           [1, 256, 64, 64]          33,024\n",
      "       Bottleneck-38           [1, 256, 64, 64]               0\n",
      "      BatchNorm2d-39           [1, 256, 64, 64]             512\n",
      "             ReLU-40           [1, 256, 64, 64]               0\n",
      "           Conv2d-41           [1, 128, 64, 64]          32,896\n",
      "      BatchNorm2d-42           [1, 128, 64, 64]             256\n",
      "             ReLU-43           [1, 128, 64, 64]               0\n",
      "           Conv2d-44           [1, 128, 64, 64]         147,584\n",
      "      BatchNorm2d-45           [1, 128, 64, 64]             256\n",
      "             ReLU-46           [1, 128, 64, 64]               0\n",
      "           Conv2d-47           [1, 256, 64, 64]          33,024\n",
      "       Bottleneck-48           [1, 256, 64, 64]               0\n",
      "      BatchNorm2d-49           [1, 256, 32, 32]             512\n",
      "             ReLU-50           [1, 256, 32, 32]               0\n",
      "           Conv2d-51           [1, 128, 32, 32]          32,896\n",
      "      BatchNorm2d-52           [1, 128, 32, 32]             256\n",
      "             ReLU-53           [1, 128, 32, 32]               0\n",
      "           Conv2d-54           [1, 128, 32, 32]         147,584\n",
      "      BatchNorm2d-55           [1, 128, 32, 32]             256\n",
      "             ReLU-56           [1, 128, 32, 32]               0\n",
      "           Conv2d-57           [1, 256, 32, 32]          33,024\n",
      "       Bottleneck-58           [1, 256, 32, 32]               0\n",
      "      BatchNorm2d-59           [1, 256, 32, 32]             512\n",
      "             ReLU-60           [1, 256, 32, 32]               0\n",
      "           Conv2d-61           [1, 128, 32, 32]          32,896\n",
      "      BatchNorm2d-62           [1, 128, 32, 32]             256\n",
      "             ReLU-63           [1, 128, 32, 32]               0\n",
      "           Conv2d-64           [1, 128, 32, 32]         147,584\n",
      "      BatchNorm2d-65           [1, 128, 32, 32]             256\n",
      "             ReLU-66           [1, 128, 32, 32]               0\n",
      "           Conv2d-67           [1, 256, 32, 32]          33,024\n",
      "       Bottleneck-68           [1, 256, 32, 32]               0\n",
      "      BatchNorm2d-69           [1, 256, 16, 16]             512\n",
      "             ReLU-70           [1, 256, 16, 16]               0\n",
      "           Conv2d-71           [1, 128, 16, 16]          32,896\n",
      "      BatchNorm2d-72           [1, 128, 16, 16]             256\n",
      "             ReLU-73           [1, 128, 16, 16]               0\n",
      "           Conv2d-74           [1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-75           [1, 128, 16, 16]             256\n",
      "             ReLU-76           [1, 128, 16, 16]               0\n",
      "           Conv2d-77           [1, 256, 16, 16]          33,024\n",
      "       Bottleneck-78           [1, 256, 16, 16]               0\n",
      "      BatchNorm2d-79           [1, 256, 16, 16]             512\n",
      "             ReLU-80           [1, 256, 16, 16]               0\n",
      "           Conv2d-81           [1, 128, 16, 16]          32,896\n",
      "      BatchNorm2d-82           [1, 128, 16, 16]             256\n",
      "             ReLU-83           [1, 128, 16, 16]               0\n",
      "           Conv2d-84           [1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-85           [1, 128, 16, 16]             256\n",
      "             ReLU-86           [1, 128, 16, 16]               0\n",
      "           Conv2d-87           [1, 256, 16, 16]          33,024\n",
      "       Bottleneck-88           [1, 256, 16, 16]               0\n",
      "      BatchNorm2d-89             [1, 256, 8, 8]             512\n",
      "             ReLU-90             [1, 256, 8, 8]               0\n",
      "           Conv2d-91             [1, 128, 8, 8]          32,896\n",
      "      BatchNorm2d-92             [1, 128, 8, 8]             256\n",
      "             ReLU-93             [1, 128, 8, 8]               0\n",
      "           Conv2d-94             [1, 128, 8, 8]         147,584\n",
      "      BatchNorm2d-95             [1, 128, 8, 8]             256\n",
      "             ReLU-96             [1, 128, 8, 8]               0\n",
      "           Conv2d-97             [1, 256, 8, 8]          33,024\n",
      "       Bottleneck-98             [1, 256, 8, 8]               0\n",
      "      BatchNorm2d-99             [1, 256, 8, 8]             512\n",
      "            ReLU-100             [1, 256, 8, 8]               0\n",
      "          Conv2d-101             [1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-102             [1, 128, 8, 8]             256\n",
      "            ReLU-103             [1, 128, 8, 8]               0\n",
      "          Conv2d-104             [1, 128, 8, 8]         147,584\n",
      "     BatchNorm2d-105             [1, 128, 8, 8]             256\n",
      "            ReLU-106             [1, 128, 8, 8]               0\n",
      "          Conv2d-107             [1, 256, 8, 8]          33,024\n",
      "      Bottleneck-108             [1, 256, 8, 8]               0\n",
      "     BatchNorm2d-109             [1, 256, 4, 4]             512\n",
      "            ReLU-110             [1, 256, 4, 4]               0\n",
      "          Conv2d-111             [1, 128, 4, 4]          32,896\n",
      "     BatchNorm2d-112             [1, 128, 4, 4]             256\n",
      "            ReLU-113             [1, 128, 4, 4]               0\n",
      "          Conv2d-114             [1, 128, 4, 4]         147,584\n",
      "     BatchNorm2d-115             [1, 128, 4, 4]             256\n",
      "            ReLU-116             [1, 128, 4, 4]               0\n",
      "          Conv2d-117             [1, 256, 4, 4]          33,024\n",
      "      Bottleneck-118             [1, 256, 4, 4]               0\n",
      "     BatchNorm2d-119             [1, 256, 4, 4]             512\n",
      "            ReLU-120             [1, 256, 4, 4]               0\n",
      "          Conv2d-121             [1, 128, 4, 4]          32,896\n",
      "     BatchNorm2d-122             [1, 128, 4, 4]             256\n",
      "            ReLU-123             [1, 128, 4, 4]               0\n",
      "          Conv2d-124             [1, 128, 4, 4]         147,584\n",
      "     BatchNorm2d-125             [1, 128, 4, 4]             256\n",
      "            ReLU-126             [1, 128, 4, 4]               0\n",
      "          Conv2d-127             [1, 256, 4, 4]          33,024\n",
      "      Bottleneck-128             [1, 256, 4, 4]               0\n",
      "     BatchNorm2d-129             [1, 256, 4, 4]             512\n",
      "            ReLU-130             [1, 256, 4, 4]               0\n",
      "          Conv2d-131             [1, 128, 4, 4]          32,896\n",
      "     BatchNorm2d-132             [1, 128, 4, 4]             256\n",
      "            ReLU-133             [1, 128, 4, 4]               0\n",
      "          Conv2d-134             [1, 128, 4, 4]         147,584\n",
      "     BatchNorm2d-135             [1, 128, 4, 4]             256\n",
      "            ReLU-136             [1, 128, 4, 4]               0\n",
      "          Conv2d-137             [1, 256, 4, 4]          33,024\n",
      "      Bottleneck-138             [1, 256, 4, 4]               0\n",
      "     BatchNorm2d-139             [1, 256, 8, 8]             512\n",
      "            ReLU-140             [1, 256, 8, 8]               0\n",
      "          Conv2d-141             [1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-142             [1, 128, 8, 8]             256\n",
      "            ReLU-143             [1, 128, 8, 8]               0\n",
      "          Conv2d-144             [1, 128, 8, 8]         147,584\n",
      "     BatchNorm2d-145             [1, 128, 8, 8]             256\n",
      "            ReLU-146             [1, 128, 8, 8]               0\n",
      "          Conv2d-147             [1, 256, 8, 8]          33,024\n",
      "      Bottleneck-148             [1, 256, 8, 8]               0\n",
      "     BatchNorm2d-149           [1, 256, 16, 16]             512\n",
      "            ReLU-150           [1, 256, 16, 16]               0\n",
      "          Conv2d-151           [1, 128, 16, 16]          32,896\n",
      "     BatchNorm2d-152           [1, 128, 16, 16]             256\n",
      "            ReLU-153           [1, 128, 16, 16]               0\n",
      "          Conv2d-154           [1, 128, 16, 16]         147,584\n",
      "     BatchNorm2d-155           [1, 128, 16, 16]             256\n",
      "            ReLU-156           [1, 128, 16, 16]               0\n",
      "          Conv2d-157           [1, 256, 16, 16]          33,024\n",
      "      Bottleneck-158           [1, 256, 16, 16]               0\n",
      "     BatchNorm2d-159           [1, 256, 32, 32]             512\n",
      "            ReLU-160           [1, 256, 32, 32]               0\n",
      "          Conv2d-161           [1, 128, 32, 32]          32,896\n",
      "     BatchNorm2d-162           [1, 128, 32, 32]             256\n",
      "            ReLU-163           [1, 128, 32, 32]               0\n",
      "          Conv2d-164           [1, 128, 32, 32]         147,584\n",
      "     BatchNorm2d-165           [1, 128, 32, 32]             256\n",
      "            ReLU-166           [1, 128, 32, 32]               0\n",
      "          Conv2d-167           [1, 256, 32, 32]          33,024\n",
      "      Bottleneck-168           [1, 256, 32, 32]               0\n",
      "       Hourglass-169           [1, 256, 64, 64]               0\n",
      "     BatchNorm2d-170           [1, 256, 64, 64]             512\n",
      "            ReLU-171           [1, 256, 64, 64]               0\n",
      "          Conv2d-172           [1, 128, 64, 64]          32,896\n",
      "     BatchNorm2d-173           [1, 128, 64, 64]             256\n",
      "            ReLU-174           [1, 128, 64, 64]               0\n",
      "          Conv2d-175           [1, 128, 64, 64]         147,584\n",
      "     BatchNorm2d-176           [1, 128, 64, 64]             256\n",
      "            ReLU-177           [1, 128, 64, 64]               0\n",
      "          Conv2d-178           [1, 256, 64, 64]          33,024\n",
      "      Bottleneck-179           [1, 256, 64, 64]               0\n",
      "          Conv2d-180           [1, 256, 64, 64]          65,792\n",
      "     BatchNorm2d-181           [1, 256, 64, 64]             512\n",
      "            ReLU-182           [1, 256, 64, 64]               0\n",
      "            ReLU-183           [1, 256, 64, 64]               0\n",
      "            ReLU-184           [1, 256, 64, 64]               0\n",
      "          Conv2d-185            [1, 16, 64, 64]           4,112\n",
      "          Conv2d-186           [1, 256, 64, 64]          65,792\n",
      "          Conv2d-187           [1, 256, 64, 64]           4,352\n",
      "     BatchNorm2d-188           [1, 256, 64, 64]             512\n",
      "            ReLU-189           [1, 256, 64, 64]               0\n",
      "          Conv2d-190           [1, 128, 64, 64]          32,896\n",
      "     BatchNorm2d-191           [1, 128, 64, 64]             256\n",
      "            ReLU-192           [1, 128, 64, 64]               0\n",
      "          Conv2d-193           [1, 128, 64, 64]         147,584\n",
      "     BatchNorm2d-194           [1, 128, 64, 64]             256\n",
      "            ReLU-195           [1, 128, 64, 64]               0\n",
      "          Conv2d-196           [1, 256, 64, 64]          33,024\n",
      "      Bottleneck-197           [1, 256, 64, 64]               0\n",
      "     BatchNorm2d-198           [1, 256, 32, 32]             512\n",
      "            ReLU-199           [1, 256, 32, 32]               0\n",
      "          Conv2d-200           [1, 128, 32, 32]          32,896\n",
      "     BatchNorm2d-201           [1, 128, 32, 32]             256\n",
      "            ReLU-202           [1, 128, 32, 32]               0\n",
      "          Conv2d-203           [1, 128, 32, 32]         147,584\n",
      "     BatchNorm2d-204           [1, 128, 32, 32]             256\n",
      "            ReLU-205           [1, 128, 32, 32]               0\n",
      "          Conv2d-206           [1, 256, 32, 32]          33,024\n",
      "      Bottleneck-207           [1, 256, 32, 32]               0\n",
      "     BatchNorm2d-208           [1, 256, 32, 32]             512\n",
      "            ReLU-209           [1, 256, 32, 32]               0\n",
      "          Conv2d-210           [1, 128, 32, 32]          32,896\n",
      "     BatchNorm2d-211           [1, 128, 32, 32]             256\n",
      "            ReLU-212           [1, 128, 32, 32]               0\n",
      "          Conv2d-213           [1, 128, 32, 32]         147,584\n",
      "     BatchNorm2d-214           [1, 128, 32, 32]             256\n",
      "            ReLU-215           [1, 128, 32, 32]               0\n",
      "          Conv2d-216           [1, 256, 32, 32]          33,024\n",
      "      Bottleneck-217           [1, 256, 32, 32]               0\n",
      "     BatchNorm2d-218           [1, 256, 16, 16]             512\n",
      "            ReLU-219           [1, 256, 16, 16]               0\n",
      "          Conv2d-220           [1, 128, 16, 16]          32,896\n",
      "     BatchNorm2d-221           [1, 128, 16, 16]             256\n",
      "            ReLU-222           [1, 128, 16, 16]               0\n",
      "          Conv2d-223           [1, 128, 16, 16]         147,584\n",
      "     BatchNorm2d-224           [1, 128, 16, 16]             256\n",
      "            ReLU-225           [1, 128, 16, 16]               0\n",
      "          Conv2d-226           [1, 256, 16, 16]          33,024\n",
      "      Bottleneck-227           [1, 256, 16, 16]               0\n",
      "     BatchNorm2d-228           [1, 256, 16, 16]             512\n",
      "            ReLU-229           [1, 256, 16, 16]               0\n",
      "          Conv2d-230           [1, 128, 16, 16]          32,896\n",
      "     BatchNorm2d-231           [1, 128, 16, 16]             256\n",
      "            ReLU-232           [1, 128, 16, 16]               0\n",
      "          Conv2d-233           [1, 128, 16, 16]         147,584\n",
      "     BatchNorm2d-234           [1, 128, 16, 16]             256\n",
      "            ReLU-235           [1, 128, 16, 16]               0\n",
      "          Conv2d-236           [1, 256, 16, 16]          33,024\n",
      "      Bottleneck-237           [1, 256, 16, 16]               0\n",
      "     BatchNorm2d-238             [1, 256, 8, 8]             512\n",
      "            ReLU-239             [1, 256, 8, 8]               0\n",
      "          Conv2d-240             [1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-241             [1, 128, 8, 8]             256\n",
      "            ReLU-242             [1, 128, 8, 8]               0\n",
      "          Conv2d-243             [1, 128, 8, 8]         147,584\n",
      "     BatchNorm2d-244             [1, 128, 8, 8]             256\n",
      "            ReLU-245             [1, 128, 8, 8]               0\n",
      "          Conv2d-246             [1, 256, 8, 8]          33,024\n",
      "      Bottleneck-247             [1, 256, 8, 8]               0\n",
      "     BatchNorm2d-248             [1, 256, 8, 8]             512\n",
      "            ReLU-249             [1, 256, 8, 8]               0\n",
      "          Conv2d-250             [1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-251             [1, 128, 8, 8]             256\n",
      "            ReLU-252             [1, 128, 8, 8]               0\n",
      "          Conv2d-253             [1, 128, 8, 8]         147,584\n",
      "     BatchNorm2d-254             [1, 128, 8, 8]             256\n",
      "            ReLU-255             [1, 128, 8, 8]               0\n",
      "          Conv2d-256             [1, 256, 8, 8]          33,024\n",
      "      Bottleneck-257             [1, 256, 8, 8]               0\n",
      "     BatchNorm2d-258             [1, 256, 4, 4]             512\n",
      "            ReLU-259             [1, 256, 4, 4]               0\n",
      "          Conv2d-260             [1, 128, 4, 4]          32,896\n",
      "     BatchNorm2d-261             [1, 128, 4, 4]             256\n",
      "            ReLU-262             [1, 128, 4, 4]               0\n",
      "          Conv2d-263             [1, 128, 4, 4]         147,584\n",
      "     BatchNorm2d-264             [1, 128, 4, 4]             256\n",
      "            ReLU-265             [1, 128, 4, 4]               0\n",
      "          Conv2d-266             [1, 256, 4, 4]          33,024\n",
      "      Bottleneck-267             [1, 256, 4, 4]               0\n",
      "     BatchNorm2d-268             [1, 256, 4, 4]             512\n",
      "            ReLU-269             [1, 256, 4, 4]               0\n",
      "          Conv2d-270             [1, 128, 4, 4]          32,896\n",
      "     BatchNorm2d-271             [1, 128, 4, 4]             256\n",
      "            ReLU-272             [1, 128, 4, 4]               0\n",
      "          Conv2d-273             [1, 128, 4, 4]         147,584\n",
      "     BatchNorm2d-274             [1, 128, 4, 4]             256\n",
      "            ReLU-275             [1, 128, 4, 4]               0\n",
      "          Conv2d-276             [1, 256, 4, 4]          33,024\n",
      "      Bottleneck-277             [1, 256, 4, 4]               0\n",
      "     BatchNorm2d-278             [1, 256, 4, 4]             512\n",
      "            ReLU-279             [1, 256, 4, 4]               0\n",
      "          Conv2d-280             [1, 128, 4, 4]          32,896\n",
      "     BatchNorm2d-281             [1, 128, 4, 4]             256\n",
      "            ReLU-282             [1, 128, 4, 4]               0\n",
      "          Conv2d-283             [1, 128, 4, 4]         147,584\n",
      "     BatchNorm2d-284             [1, 128, 4, 4]             256\n",
      "            ReLU-285             [1, 128, 4, 4]               0\n",
      "          Conv2d-286             [1, 256, 4, 4]          33,024\n",
      "      Bottleneck-287             [1, 256, 4, 4]               0\n",
      "     BatchNorm2d-288             [1, 256, 8, 8]             512\n",
      "            ReLU-289             [1, 256, 8, 8]               0\n",
      "          Conv2d-290             [1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-291             [1, 128, 8, 8]             256\n",
      "            ReLU-292             [1, 128, 8, 8]               0\n",
      "          Conv2d-293             [1, 128, 8, 8]         147,584\n",
      "     BatchNorm2d-294             [1, 128, 8, 8]             256\n",
      "            ReLU-295             [1, 128, 8, 8]               0\n",
      "          Conv2d-296             [1, 256, 8, 8]          33,024\n",
      "      Bottleneck-297             [1, 256, 8, 8]               0\n",
      "     BatchNorm2d-298           [1, 256, 16, 16]             512\n",
      "            ReLU-299           [1, 256, 16, 16]               0\n",
      "          Conv2d-300           [1, 128, 16, 16]          32,896\n",
      "     BatchNorm2d-301           [1, 128, 16, 16]             256\n",
      "            ReLU-302           [1, 128, 16, 16]               0\n",
      "          Conv2d-303           [1, 128, 16, 16]         147,584\n",
      "     BatchNorm2d-304           [1, 128, 16, 16]             256\n",
      "            ReLU-305           [1, 128, 16, 16]               0\n",
      "          Conv2d-306           [1, 256, 16, 16]          33,024\n",
      "      Bottleneck-307           [1, 256, 16, 16]               0\n",
      "     BatchNorm2d-308           [1, 256, 32, 32]             512\n",
      "            ReLU-309           [1, 256, 32, 32]               0\n",
      "          Conv2d-310           [1, 128, 32, 32]          32,896\n",
      "     BatchNorm2d-311           [1, 128, 32, 32]             256\n",
      "            ReLU-312           [1, 128, 32, 32]               0\n",
      "          Conv2d-313           [1, 128, 32, 32]         147,584\n",
      "     BatchNorm2d-314           [1, 128, 32, 32]             256\n",
      "            ReLU-315           [1, 128, 32, 32]               0\n",
      "          Conv2d-316           [1, 256, 32, 32]          33,024\n",
      "      Bottleneck-317           [1, 256, 32, 32]               0\n",
      "       Hourglass-318           [1, 256, 64, 64]               0\n",
      "     BatchNorm2d-319           [1, 256, 64, 64]             512\n",
      "            ReLU-320           [1, 256, 64, 64]               0\n",
      "          Conv2d-321           [1, 128, 64, 64]          32,896\n",
      "     BatchNorm2d-322           [1, 128, 64, 64]             256\n",
      "            ReLU-323           [1, 128, 64, 64]               0\n",
      "          Conv2d-324           [1, 128, 64, 64]         147,584\n",
      "     BatchNorm2d-325           [1, 128, 64, 64]             256\n",
      "            ReLU-326           [1, 128, 64, 64]               0\n",
      "          Conv2d-327           [1, 256, 64, 64]          33,024\n",
      "      Bottleneck-328           [1, 256, 64, 64]               0\n",
      "          Conv2d-329           [1, 256, 64, 64]          65,792\n",
      "     BatchNorm2d-330           [1, 256, 64, 64]             512\n",
      "            ReLU-331           [1, 256, 64, 64]               0\n",
      "            ReLU-332           [1, 256, 64, 64]               0\n",
      "            ReLU-333           [1, 256, 64, 64]               0\n",
      "          Conv2d-334            [1, 16, 64, 64]           4,112\n",
      "================================================================\n",
      "Total params: 6,730,912\n",
      "Trainable params: 6,730,912\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 716.56\n",
      "Params size (MB): 25.68\n",
      "Estimated Total Size (MB): 742.99\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 2 stacked hourglass\n",
    "model = HourglassNet(Bottleneck, num_stacks=2, num_blocks=1, num_classes=16).to(device)\n",
    "\n",
    "summary(model, input_size=(3, 256, 256), batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Baselines (2018)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt15",
   "language": "python",
   "name": "pt15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
